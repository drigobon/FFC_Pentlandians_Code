{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Create Random Forest Predictions using 3-fold Cross-Validation to determine best model predictions and best model parameters\n",
    "# Inputs: Feature Selection file from MI, K value specified in string (100 used for best predictions)\n",
    "# Outputs: Prediction files for best RF, average best RF, and weighted best RF by CV score\n",
    "# Machine: High-performance Cluster (64 cores), ~4 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss, mean_squared_error\n",
    "from scipy.stats import randint, uniform ### IMPORTANT: these are distributions and not draws\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##loading the data\n",
    "dfx = pd.read_csv('../output/MI/data_univariate_feature_selection_100.csv',index_col='challengeID')\n",
    "dfy = pd.read_csv('../data/train.csv',index_col='challengeID')\n",
    "  \n",
    "predictions = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,'grit':None,'materialHardship':None,'eviction':None,'layoff':None,'jobTraining':None}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##scaling X\n",
    "for col in dfx.columns:\n",
    "    dfx[col] = (dfx[col] - dfx[col].mean())/dfx[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcomes = list(dfy.columns) #get the names of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randint(1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_MODELS = 200\n",
    "n_CVjobs = 10\n",
    "n_CVsplits = 5\n",
    "n_modelJobs = 10 #*4 ##remove the comment on EC2\n",
    "mode = None\n",
    "n_iter_search = 50\n",
    "max_features = 15 ##this should be < n_features\n",
    "\n",
    "reg_outcomes = ['gpa', 'grit', 'materialHardship']\n",
    "clf_outcomes = [ 'eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__reg_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'oob_score':[True,False]}\n",
    "\n",
    "__clf_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'criterion':['gini','entropy']}\n",
    "\n",
    "\n",
    "###### We don't use this anymore (where we average the parameters of the model)####\n",
    "#__reg_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'oob_score':[]}\n",
    "#\n",
    "#__clf_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'criterion':[]}\n",
    "#best_param = {'reg' : __reg_param,\n",
    "#              'clf': __clf_param}\n",
    "\n",
    "param_dist = {'reg' : __reg_param_dist,\n",
    "              'clf': __clf_param_dist}\n",
    "\n",
    "model = {'reg' : RandomForestRegressor(n_jobs=n_modelJobs),\n",
    "          'clf': RandomForestClassifier(n_jobs=n_modelJobs)}\n",
    "\n",
    "scorer = {'reg' : make_scorer(mean_squared_error,greater_is_better=False),\n",
    "           'clf' : make_scorer(brier_score_loss,greater_is_better=False)}\n",
    "\n",
    "evaluate_error = {'reg': mean_squared_error,\n",
    "                  'clf': brier_score_loss}\n",
    "\n",
    "\n",
    "best_model_prediction = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,\n",
    "               'grit':None,\n",
    "               'materialHardship':None,\n",
    "               'eviction':None,\n",
    "               'layoff': None,\n",
    "               'jobTraining':None\n",
    "              }\n",
    "\n",
    "avg_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "weighted_models_prediction = copy.deepcopy(best_model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for outcome in outcomes:\n",
    "    ##Figure out in what mode we are\n",
    "    if outcome in reg_outcomes:\n",
    "        mode = 'reg'\n",
    "    else:\n",
    "        mode = 'clf'\n",
    "    \n",
    "    ###prepare X and Y####\n",
    "    full = dfx.join(dfy, how='outer') #connect the background data to outcomes\n",
    "    full_X = full.copy()\n",
    "    for inner_outcome in outcomes:\n",
    "        del full[inner_outcome]\n",
    "    X = full_X.dropna(subset=[outcome], how='all')\n",
    "    y = X[outcome]\n",
    "    for inner_outcome in outcomes:\n",
    "        del full_X[inner_outcome]\n",
    "\n",
    "    for inner_outcome in outcomes:\n",
    "        del X[inner_outcome]\n",
    "        \n",
    "    ##In order to try the different aggregation mechanisms\n",
    "    combined_model_prediction = {'challengeID':np.array(list(dfx.index)),outcome: None}\n",
    "    lowest_error = np.inf\n",
    "    best_model = None\n",
    "    all_models_scores = []\n",
    "    weighted_models = [] \n",
    "    n_good_models = 0\n",
    "\n",
    "    for i in range(1,NUM_MODELS+1):\n",
    "        print('at loop:',i,'for outcome ', outcome)\n",
    "        ##prepare the nested CV\n",
    "        inner_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "\n",
    "        ########Nested CV with parameter optimization########\n",
    "        #the Randomized search for the best parameters through cross validation\n",
    "        search = RandomizedSearchCV(estimator=model[mode], param_distributions=param_dist[mode],\n",
    "                                    scoring = scorer[mode],\n",
    "                                    cv=inner_cv,n_jobs=n_CVjobs,n_iter=n_iter_search)\n",
    "        search.fit(X, y)\n",
    "        #The evaluation of the best model found by the inner CV by having an outer CV\n",
    "        nested_score = cross_val_score(search, X=X, y=y, cv=outer_cv)\n",
    "        if mode == 'reg':\n",
    "            prediction = search.best_estimator_.predict(X)\n",
    "        else:\n",
    "            prediction = search.best_estimator_.predict_proba(X)[:,1]\n",
    "\n",
    "        if evaluate_error[mode](y,prediction) < np.inf:\n",
    "            n_good_models +=1\n",
    "\n",
    "            if evaluate_error[mode](y,prediction) < lowest_error:\n",
    "                print('best so far')\n",
    "                lowest_error = evaluate_error[mode](y,prediction)\n",
    "                best_model = search.best_estimator_\n",
    "\n",
    "            if i == 1:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "            else:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome] + search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome]+ search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "\n",
    "                \n",
    "\n",
    "            all_models_scores.append(evaluate_error[mode](y,prediction))\n",
    "            if mode == 'reg':\n",
    "                weighted_models.append(search.best_estimator_.predict(full_X))\n",
    "            else:\n",
    "                weighted_models.append(search.best_estimator_.predict_proba(full_X)[:,1])\n",
    "        print('score:', evaluate_error[mode](y,prediction))\n",
    "        print('CV scores:', nested_score.mean(), nested_score)\n",
    "        print('best params', search.best_params_)\n",
    "        print('#######')\n",
    "    \n",
    "\n",
    "        \n",
    "        ##best model prediction\n",
    "        best_model.fit(X, y)\n",
    "        if mode == 'reg':\n",
    "            final_prediction = best_model.predict(full_X)\n",
    "        else:\n",
    "            final_prediction = best_model.predict_proba(full_X)[:,1]\n",
    "        best_model_prediction[outcome] = final_prediction\n",
    "        \n",
    "        ##avg models prediction\n",
    "        avg_models_prediction[outcome] = combined_model_prediction[outcome]/float(n_good_models)\n",
    "        \n",
    "        \n",
    "        ##weighted models prediction\n",
    "        scores = np.array(all_models_scores)\n",
    "        normlized_scores = scores/sum(scores)\n",
    "        normlized_scores = normlized_scores.reshape(normlized_scores.shape[0],1)\n",
    "        models_predicitons = np.matrix(weighted_models).T\n",
    "        weighted_prediction = np.array(models_predicitons*normlized_scores).flatten().tolist()\n",
    "        weighted_models_prediction[outcome] = weighted_prediction\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_best = pd.DataFrame.from_dict(best_model_prediction)\n",
    "df_avg = pd.DataFrame.from_dict(avg_models_prediction)\n",
    "df_weighted = pd.DataFrame.from_dict(weighted_models_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_best.to_csv('../output/final_pred/best_multiRF_prediction.csv',index=False)\n",
    "#df_avg.to_csv('../output/final_pred/avg_multiRF_prediction.csv',index=False)\n",
    "df_weighted.to_csv('../output/final_pred/weighted_multiRF_prediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
