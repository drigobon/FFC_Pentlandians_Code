{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Aggregate Individual Predictions from Elastic Net, GBT, and both implementations of Random Forest\n",
    "# Inputs: Predictions from Lasso RF, Weighted Multiple Random Forest, Elastic Net, and Gradient-boosted Tree\n",
    "# Outputs: Simple Team Average, ad-hoc Weighted Average (from LB performance), best Linear Regression Ensemble, best Random Forest Ensemble\n",
    "# Machine: High-performance Cluster (64 cores), ~1 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss, mean_squared_error\n",
    "from scipy.stats import randint, uniform ### IMPORTANT: these are distributions and not draws\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_abdul = pd.read_csv('../output/final_pred/weighted_multiRF_prediction.csv',index_col='challengeID')\n",
    "df_dan = pd.read_csv('../output/final_pred/lassoRF_prediction.csv',index_col='challengeID')\n",
    "df_eaman = pd.read_csv('../output/final_pred/elastic_prediction.csv',index_col='challengeID')\n",
    "df_yoshi = pd.read_csv('../output/final_pred/xgboost_prediction.csv',index_col='challengeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_prediction = (df_abdul + df_dan + df_eaman+df_yoshi)/4\n",
    "average_prediction.eviction = (df_abdul.eviction+df_dan.eviction+df_yoshi.eviction)/3\n",
    "average_prediction.layoff = (df_abdul.layoff+df_dan.layoff+df_yoshi.layoff)/3\n",
    "average_prediction.jobTraining = (df_yoshi.jobTraining + df_dan.jobTraining+df_abdul.jobTraining)/3.\n",
    "\n",
    "average_prediction.to_csv('../output/final_pred/avrg_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Weighted Avg Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted_prediction = (3*df_abdul + 2*df_eaman + df_yoshi)/6\n",
    "weighted_prediction.gpa = (3*df_eaman.gpa + 2*df_abdul.gpa + df_dan.gpa)/6\n",
    "weighted_prediction.grit = (3*df_eaman.grit + 2*df_dan.grit + df_abdul.grit)/6\n",
    "weighted_prediction.layoff = (2*df_abdul.layoff + df_dan.layoff)/3\n",
    "weighted_prediction.eviction = (2*df_abdul.eviction + df_dan.eviction)/3\n",
    "weighted_prediction.jobTraining = (3*df_abdul + 2*df_yoshi + df_dan)/6\n",
    "\n",
    "weighted_prediction.to_csv('../output/final_pred/weighted_avrg_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df_abdul.columns:\n",
    "    df_abdul[col+'_abdul'] = df_abdul[col]\n",
    "    del df_abdul[col]\n",
    "    \n",
    "for col in df_dan.columns:\n",
    "    df_dan[col+'_dan'] = df_dan[col]\n",
    "    del df_dan[col]\n",
    "    \n",
    "for col in df_eaman.columns:\n",
    "    df_eaman[col+'_eaman'] = df_eaman[col]\n",
    "    del df_eaman[col]\n",
    "\n",
    "dfx = df_abdul.join(df_eaman).join(df_dan)\n",
    "dfy = pd.read_csv('../data/train.csv',index_col='challengeID')\n",
    "predictions = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,'grit':None,'materialHardship':None,'eviction':None,'layoff':None,'jobTraining':None}  \n",
    "outcomes = list(dfy.columns) #get the names of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 10\n",
    "n_CVjobs = 9\n",
    "n_CVsplits = 5\n",
    "n_modelJobs = 7 #*4 ##remove the comment on EC2\n",
    "mode = None\n",
    "n_iter_search = 30\n",
    "max_features = 18 ##this should be < n_features\n",
    "\n",
    "reg_outcomes = ['gpa', 'grit', 'materialHardship']\n",
    "clf_outcomes = [ 'eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__reg_param_dist = {\"fit_intercept\":[True,False], \"normalize\":[True,False]}\n",
    "\n",
    "__clf_param_dist = { \"C\":[0.001,0.00001,1.0,10], \"fit_intercept\":[True,False]}\n",
    "\n",
    "\n",
    "###### We don't use this anymore (where we average the parameters of the model)####\n",
    "#__reg_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'oob_score':[]}\n",
    "#\n",
    "#__clf_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'criterion':[]}\n",
    "#best_param = {'reg' : __reg_param,\n",
    "#              'clf': __clf_param}\n",
    "\n",
    "param_dist = {'reg' : __reg_param_dist,\n",
    "              'clf': __clf_param_dist}\n",
    "\n",
    "model = {'reg' : LinearRegression(),\n",
    "          'clf': LogisticRegression()}\n",
    "\n",
    "scorer = {'reg' : make_scorer(mean_squared_error,greater_is_better=False),\n",
    "           'clf' : make_scorer(brier_score_loss,greater_is_better=False)}\n",
    "\n",
    "evaluate_error = {'reg': mean_squared_error,\n",
    "                  'clf': brier_score_loss}\n",
    "\n",
    "\n",
    "best_model_prediction = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,\n",
    "               'grit':None,\n",
    "               'materialHardship':None,\n",
    "               'eviction':None,\n",
    "               'layoff': None,\n",
    "               'jobTraining':None\n",
    "              }\n",
    "\n",
    "avg_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "weighted_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "\n",
    "\n",
    "\n",
    "for outcome in outcomes:\n",
    "    ##Figure out in what mode we are\n",
    "    if outcome in reg_outcomes:\n",
    "        mode = 'reg'\n",
    "    else:\n",
    "        mode = 'clf'\n",
    "    \n",
    "    ###prepare X and Y####\n",
    "    full = dfx.join(dfy, how='outer') #connect the background data to outcomes\n",
    "    full_X = full.copy()\n",
    "    for inner_outcome in outcomes:\n",
    "        del full[inner_outcome]\n",
    "    X = full_X.dropna(subset=[outcome], how='all')\n",
    "    y = X[outcome]\n",
    "    for inner_outcome in outcomes:\n",
    "        del full_X[inner_outcome]\n",
    "\n",
    "    for inner_outcome in outcomes:\n",
    "        del X[inner_outcome]\n",
    "        \n",
    "    ##In order to try the different aggregation mechanisms\n",
    "    combined_model_prediction = {'challengeID':np.array(list(dfx.index)),outcome: None}\n",
    "    lowest_error = np.inf\n",
    "    best_model = None\n",
    "    all_models_scores = []\n",
    "    weighted_models = [] \n",
    "    n_good_models = 0\n",
    "\n",
    "    for i in range(1,NUM_MODELS+1):\n",
    "        print('at loop:',i,'for outcome ', outcome)\n",
    "        ##prepare the nested CV\n",
    "        inner_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "\n",
    "        ########Nested CV with parameter optimization########\n",
    "        #the Randomized search for the best parameters through cross validation\n",
    "        search = GridSearchCV(estimator=model[mode], param_grid=param_dist[mode],\n",
    "                                    scoring = scorer[mode],\n",
    "                                    cv=inner_cv,n_jobs=n_CVjobs)\n",
    "        search.fit(X, y)\n",
    "        #The evaluation of the best model found by the inner CV by having an outer CV\n",
    "        nested_score = cross_val_score(search, X=X, y=y, cv=outer_cv)\n",
    "        if mode == 'reg':\n",
    "            prediction = search.best_estimator_.predict(X)\n",
    "        else:\n",
    "            prediction = search.best_estimator_.predict_proba(X)[:,1]\n",
    "\n",
    "        if evaluate_error[mode](y,prediction) < np.inf:\n",
    "            n_good_models +=1\n",
    "\n",
    "            if evaluate_error[mode](y,prediction) < lowest_error:\n",
    "                print('best so far')\n",
    "                lowest_error = evaluate_error[mode](y,prediction)\n",
    "                best_model = search.best_estimator_\n",
    "\n",
    "            if i == 1:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "            else:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome] + search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome]+ search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "\n",
    "                \n",
    "\n",
    "            all_models_scores.append(evaluate_error[mode](y,prediction))\n",
    "            if mode == 'reg':\n",
    "                weighted_models.append(search.best_estimator_.predict(full_X))\n",
    "            else:\n",
    "                weighted_models.append(search.best_estimator_.predict_proba(full_X)[:,1])\n",
    "        print('score:', evaluate_error[mode](y,prediction))\n",
    "        print('CV scores:', nested_score.mean(), nested_score)\n",
    "        print('best params', search.best_params_)\n",
    "        print('#######')\n",
    "    \n",
    "\n",
    "        \n",
    "        ##best model prediction\n",
    "        best_model.fit(X, y)\n",
    "        if mode == 'reg':\n",
    "            final_prediction = best_model.predict(full_X)\n",
    "        else:\n",
    "            final_prediction = best_model.predict_proba(full_X)[:,1]\n",
    "        best_model_prediction[outcome] = final_prediction\n",
    "        \n",
    "        ##avg models prediction\n",
    "        avg_models_prediction[outcome] = combined_model_prediction[outcome]/float(n_good_models)\n",
    "        \n",
    "        \n",
    "        ##weighted models prediction\n",
    "        scores = np.array(all_models_scores)\n",
    "        normlized_scores = scores/sum(scores)\n",
    "        normlized_scores = normlized_scores.reshape(normlized_scores.shape[0],1)\n",
    "        models_predicitons = np.matrix(weighted_models).T\n",
    "        weighted_prediction = np.array(models_predicitons*normlized_scores).flatten().tolist()\n",
    "        weighted_models_prediction[outcome] = weighted_prediction\n",
    "\n",
    "df_best = pd.DataFrame.from_dict(best_model_prediction)\n",
    "df_avg = pd.DataFrame.from_dict(avg_models_prediction)\n",
    "df_weighted = pd.DataFrame.from_dict(weighted_models_prediction)\n",
    "\n",
    "df_best.to_csv('../output/final_pred/LR_prediction.csv')\n",
    "#df_avg.to_csv('./Linear_avg_prediction.csv',index=False)\n",
    "#df_weighted.to_csv('./Linear_weighted_prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ensemble (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 50\n",
    "n_CVjobs = 9\n",
    "n_CVsplits = 5\n",
    "n_modelJobs = 7 #*4 ##remove the comment on EC2\n",
    "mode = None\n",
    "n_iter_search = 30\n",
    "max_features = 15 ##this should be the number of features / 5\n",
    "\n",
    "reg_outcomes = ['gpa', 'grit', 'materialHardship']\n",
    "clf_outcomes = [ 'eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__reg_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'oob_score':[True,False]}\n",
    "\n",
    "__clf_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'criterion':['gini','entropy']}\n",
    "\n",
    "\n",
    "###### We don't use this anymore (where we average the parameters of the model)####\n",
    "#__reg_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'oob_score':[]}\n",
    "#\n",
    "#__clf_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'criterion':[]}\n",
    "#best_param = {'reg' : __reg_param,\n",
    "#              'clf': __clf_param}\n",
    "\n",
    "param_dist = {'reg' : __reg_param_dist,\n",
    "              'clf': __clf_param_dist}\n",
    "\n",
    "model = {'reg' : RandomForestRegressor(n_jobs=n_modelJobs),\n",
    "          'clf': RandomForestClassifier(n_jobs=n_modelJobs)}\n",
    "\n",
    "scorer = {'reg' : make_scorer(mean_squared_error,greater_is_better=False),\n",
    "           'clf' : make_scorer(brier_score_loss,greater_is_better=False)}\n",
    "\n",
    "evaluate_error = {'reg': mean_squared_error,\n",
    "                  'clf': brier_score_loss}\n",
    "\n",
    "\n",
    "best_model_prediction = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,\n",
    "               'grit':None,\n",
    "               'materialHardship':None,\n",
    "               'eviction':None,\n",
    "               'layoff': None,\n",
    "               'jobTraining':None\n",
    "              }\n",
    "\n",
    "avg_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "weighted_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "\n",
    "\n",
    "for outcome in outcomes:\n",
    "    ##Figure out in what mode we are\n",
    "    if outcome in reg_outcomes:\n",
    "        mode = 'reg'\n",
    "    else:\n",
    "        mode = 'clf'\n",
    "    \n",
    "    ###prepare X and Y####\n",
    "    full = dfx.join(dfy, how='outer') #connect the background data to outcomes\n",
    "    full_X = full.copy()\n",
    "    for inner_outcome in outcomes:\n",
    "        del full[inner_outcome]\n",
    "    X = full_X.dropna(subset=[outcome], how='all')\n",
    "    y = X[outcome]\n",
    "    for inner_outcome in outcomes:\n",
    "        del full_X[inner_outcome]\n",
    "\n",
    "    for inner_outcome in outcomes:\n",
    "        del X[inner_outcome]\n",
    "        \n",
    "    ##In order to try the different aggregation mechanisms\n",
    "    combined_model_prediction = {'challengeID':np.array(list(dfx.index)),outcome: None}\n",
    "    lowest_error = np.inf\n",
    "    best_model = None\n",
    "    all_models_scores = []\n",
    "    weighted_models = [] \n",
    "    n_good_models = 0\n",
    "\n",
    "    for i in range(1,NUM_MODELS+1):\n",
    "        print('at loop:',i,'for outcome ', outcome)\n",
    "        ##prepare the nested CV\n",
    "        inner_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "\n",
    "        ########Nested CV with parameter optimization########\n",
    "        #the Randomized search for the best parameters through cross validation\n",
    "        search = RandomizedSearchCV(estimator=model[mode], param_distributions=param_dist[mode],\n",
    "                                    scoring = scorer[mode],\n",
    "                                    cv=inner_cv,n_jobs=n_CVjobs,n_iter=n_iter_search)\n",
    "        search.fit(X, y)\n",
    "        #The evaluation of the best model found by the inner CV by having an outer CV\n",
    "        nested_score = cross_val_score(search, X=X, y=y, cv=outer_cv)\n",
    "        if mode == 'reg':\n",
    "            prediction = search.best_estimator_.predict(X)\n",
    "        else:\n",
    "            prediction = search.best_estimator_.predict_proba(X)[:,1]\n",
    "\n",
    "        if evaluate_error[mode](y,prediction) < np.inf:\n",
    "            n_good_models +=1\n",
    "\n",
    "            if evaluate_error[mode](y,prediction) < lowest_error:\n",
    "                print('best so far')\n",
    "                lowest_error = evaluate_error[mode](y,prediction)\n",
    "                best_model = search.best_estimator_\n",
    "\n",
    "            if i == 1:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "            else:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome] + search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome]+ search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "\n",
    "                \n",
    "\n",
    "            all_models_scores.append(evaluate_error[mode](y,prediction))\n",
    "            if mode == 'reg':\n",
    "                weighted_models.append(search.best_estimator_.predict(full_X))\n",
    "            else:\n",
    "                weighted_models.append(search.best_estimator_.predict_proba(full_X)[:,1])\n",
    "        print('score:', evaluate_error[mode](y,prediction))\n",
    "        print('CV scores:', nested_score.mean(), nested_score)\n",
    "        print('best params', search.best_params_)\n",
    "        print('#######')\n",
    "    \n",
    "\n",
    "        \n",
    "        ##best model prediction\n",
    "        best_model.fit(X, y)\n",
    "        if mode == 'reg':\n",
    "            final_prediction = best_model.predict(full_X)\n",
    "        else:\n",
    "            final_prediction = best_model.predict_proba(full_X)[:,1]\n",
    "        best_model_prediction[outcome] = final_prediction\n",
    "        \n",
    "        ##avg models prediction\n",
    "        avg_models_prediction[outcome] = combined_model_prediction[outcome]/float(n_good_models)\n",
    "        \n",
    "        \n",
    "        ##weighted models prediction\n",
    "        scores = np.array(all_models_scores)\n",
    "        normlized_scores = scores/sum(scores)\n",
    "        normlized_scores = normlized_scores.reshape(normlized_scores.shape[0],1)\n",
    "        models_predicitons = np.matrix(weighted_models).T\n",
    "        weighted_prediction = np.array(models_predicitons*normlized_scores).flatten().tolist()\n",
    "        weighted_models_prediction[outcome] = weighted_prediction\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "df_best = pd.DataFrame.from_dict(best_model_prediction)\n",
    "df_avg = pd.DataFrame.from_dict(avg_models_prediction)\n",
    "df_weighted = pd.DataFrame.from_dict(weighted_models_prediction)\n",
    "\n",
    "df_best.to_csv('../output/final_pred/RF_prediction.csv')\n",
    "#df_avg.to_csv(output_file+'/avg_prediction/prediction.csv')\n",
    "#df_weighted.to_csv(output_file+'/weighted_prediction/prediction.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
