{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Aggregate Individual Predictions from Elastic Net, GBT, and both implementations of Random Forest\n",
    "# Inputs: Predictions from Lasso RF, Weighted Multiple Random Forest, Elastic Net, and Gradient-boosted Tree\n",
    "# Outputs: Simple Team Average, ad-hoc Weighted Average (from LB performance), best Linear Regression Ensemble, best Random Forest Ensemble\n",
    "# Machine: High-performance Cluster (64 cores), ~1 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages Used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss, mean_squared_error\n",
    "from scipy.stats import randint, uniform ### IMPORTANT: these are distributions and not draws\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abdul = pd.read_csv('../output/final_pred/weighted_multiRF_prediction.csv',index_col='challengeID')\n",
    "df_dan = pd.read_csv('../output/final_pred/lassoRF_prediction.csv',index_col='challengeID')\n",
    "df_eaman = pd.read_csv('../output/final_pred/elastic_prediction.csv',index_col='challengeID')\n",
    "df_yoshi = pd.read_csv('../output/final_pred/xgboost_prediction.csv',index_col='challengeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_prediction = (df_abdul + df_dan + df_eaman+df_yoshi)/4\n",
    "average_prediction.eviction = (df_abdul.eviction+df_dan.eviction+df_yoshi.eviction)/3\n",
    "average_prediction.layoff = (df_abdul.layoff+df_dan.layoff+df_yoshi.layoff)/3\n",
    "average_prediction.jobTraining = (df_yoshi.jobTraining + df_dan.jobTraining+df_abdul.jobTraining)/3.\n",
    "\n",
    "average_prediction.to_csv('../output/final_pred/avrg_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Weighted Avg Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted_prediction = (3*df_abdul + 2*df_eaman + df_yoshi)/6\n",
    "weighted_prediction.gpa = (3*df_eaman.gpa + 2*df_abdul.gpa + df_dan.gpa)/6\n",
    "weighted_prediction.grit = (3*df_eaman.grit + 2*df_dan.grit + df_abdul.grit)/6\n",
    "weighted_prediction.layoff = (2*df_abdul.layoff + df_dan.layoff)/3\n",
    "weighted_prediction.eviction = (2*df_abdul.eviction + df_dan.eviction)/3\n",
    "weighted_prediction.jobTraining = (3*df_abdul + 2*df_yoshi + df_dan)/6\n",
    "\n",
    "weighted_prediction.to_csv('../output/final_pred/weighted_avrg_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df_abdul.columns:\n",
    "    df_abdul[col+'_abdul'] = df_abdul[col]\n",
    "    del df_abdul[col]\n",
    "    \n",
    "for col in df_dan.columns:\n",
    "    df_dan[col+'_dan'] = df_dan[col]\n",
    "    del df_dan[col]\n",
    "    \n",
    "for col in df_eaman.columns:\n",
    "    df_eaman[col+'_eaman'] = df_eaman[col]\n",
    "    del df_eaman[col]\n",
    "\n",
    "dfx = df_abdul.join(df_eaman).join(df_dan)\n",
    "dfy = pd.read_csv('../data/train.csv',index_col='challengeID')\n",
    "predictions = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,'grit':None,'materialHardship':None,'eviction':None,'layoff':None,'jobTraining':None}  \n",
    "outcomes = list(dfy.columns) #get the names of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at loop: 1 for outcome  gpa\n",
      "best so far\n",
      "score: 0.0124570426475\n",
      "CV scores: -1.75089160221 [-0.0134401  -0.01361169 -8.7041309  -0.01238989 -0.01088542]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 2 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0128019691045 [-0.01294373 -0.01404033 -0.01340153 -0.01172618 -0.01189808]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 3 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0129101445572 [-0.01225124 -0.01357717 -0.01156618 -0.01356161 -0.01359453]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 4 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0129199912603 [-0.01379953 -0.01133819 -0.01282343 -0.01318793 -0.01345087]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 5 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0128032952029 [-0.01333758 -0.01480875 -0.01242337 -0.01071327 -0.01273351]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 6 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.01289084889 [-0.01193107 -0.01183569 -0.01427723 -0.01233876 -0.0140715 ]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 7 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0127995845559 [-0.01115072 -0.01259826 -0.01443075 -0.01281926 -0.01299893]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 8 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0128650973715 [-0.01319613 -0.01314765 -0.01206489 -0.01462946 -0.01128736]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 9 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0128625654012 [-0.01417973 -0.012396   -0.01119208 -0.01327839 -0.01326663]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 10 for outcome  gpa\n",
      "score: 0.0124570426475\n",
      "CV scores: -0.0129168161379 [-0.01378983 -0.01199501 -0.01269054 -0.01182886 -0.01427984]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 1 for outcome  grit\n",
      "best so far\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106559056042 [-0.01112163 -0.0074723  -0.01015512 -0.01276765 -0.01176284]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 2 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0107564224093 [-0.00969176 -0.01111526 -0.01135524 -0.00991413 -0.01170571]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 3 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106874628816 [-0.01043129 -0.01024308 -0.00881709 -0.01276607 -0.01117979]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 4 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0107102446768 [-0.01352139 -0.00906385 -0.00988322 -0.00892023 -0.01216254]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 5 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106564436109 [-0.0094738  -0.01245562 -0.00869741 -0.01161328 -0.01104212]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 6 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106564736906 [-0.00816349 -0.01109733 -0.01253795 -0.01290132 -0.00858228]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 7 for outcome  grit\n",
      "best so far\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106608729234 [-0.01171786 -0.01017064 -0.01089126 -0.01002675 -0.01049785]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 8 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106981042533 [-0.0082062  -0.01120642 -0.01018052 -0.01520787 -0.00868951]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 9 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0106295824269 [-0.00952176 -0.01368252 -0.00875726 -0.00922707 -0.0119593 ]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 10 for outcome  grit\n",
      "score: 0.0104151570757\n",
      "CV scores: -0.0105847507321 [-0.00791921 -0.01009066 -0.01114406 -0.01170611 -0.01206371]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 1 for outcome  materialHardship\n",
      "best so far\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00171842729858 [-0.00214183 -0.00174629 -0.00173052 -0.00136905 -0.00160445]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 2 for outcome  materialHardship\n",
      "best so far\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00174235922528 [-0.00199296 -0.00167435 -0.0015557  -0.00175422 -0.00173457]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 3 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00172414802187 [-0.0020062  -0.00171706 -0.00153263 -0.00156489 -0.00179997]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 4 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00173408505869 [-0.00203689 -0.00162355 -0.00192232 -0.00160195 -0.00148571]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 5 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00172714190911 [-0.00210566 -0.00157881 -0.00159319 -0.00160827 -0.00174978]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 6 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00172755336765 [-0.0017857  -0.00172572 -0.00147147 -0.00215094 -0.00150395]\n",
      "best params {'fit_intercept': True, 'normalize': True}\n",
      "#######\n",
      "at loop: 7 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00171591004449 [-0.00188064 -0.00161147 -0.00173417 -0.00163477 -0.0017185 ]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 8 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00173217747964 [-0.00186623 -0.00152259 -0.00211177 -0.00171441 -0.00144588]\n",
      "best params {'fit_intercept': False, 'normalize': True}\n",
      "#######\n",
      "at loop: 9 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00170389779753 [-0.00169474 -0.00189656 -0.00147689 -0.00175899 -0.00169232]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 10 for outcome  materialHardship\n",
      "score: 0.0016663510069\n",
      "CV scores: -0.00172663787796 [-0.00181759 -0.00152806 -0.00163477 -0.00187412 -0.00177864]\n",
      "best params {'fit_intercept': True, 'normalize': False}\n",
      "#######\n",
      "at loop: 1 for outcome  eviction\n",
      "best so far\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.017813119407 [-0.02389078 -0.01706485 -0.0137457  -0.02405498 -0.01030928]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 2 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0184863305302 [-0.03412969 -0.01706485 -0.01030928 -0.02405498 -0.00687285]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 3 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0185050959971 [-0.02047782 -0.01706485 -0.0137457  -0.02061856 -0.02061856]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 4 for outcome  eviction\n",
      "best so far\n",
      "score: 0.0136034340233\n",
      "CV scores: -0.0178178107737 [-0.02389078 -0.01365188 -0.01030928 -0.02749141 -0.0137457 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 5 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.019860900977 [-0.03071672 -0.02047782 -0.01718213 -0.02405498 -0.00687285]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 6 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0178178107737 [-0.01023891 -0.02730375 -0.02405498 -0.01030928 -0.01718213]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 7 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0178178107737 [-0.02389078 -0.01365188 -0.02405498 -0.02061856 -0.00687285]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 8 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0185191700972 [-0.01023891 -0.01706485 -0.02061856 -0.01718213 -0.02749141]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 9 for outcome  eviction\n",
      "score: 0.0143468949357\n",
      "CV scores: -0.0178318848739 [-0.00341297 -0.02389078 -0.02061856 -0.02749141 -0.0137457 ]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 10 for outcome  eviction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.0143468949357\n",
      "CV scores: -0.0198562096103 [-0.02389078 -0.03071672 -0.01718213 -0.01718213 -0.01030928]\n",
      "best params {'C': 1.0, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 1 for outcome  layoff\n",
      "best so far\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0579258578431 [-0.06640625 -0.078125   -0.05882353 -0.03921569 -0.04705882]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 2 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0571691176471 [-0.07421875 -0.03515625 -0.05490196 -0.05882353 -0.0627451 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 3 for outcome  layoff\n",
      "score: 0.039684323691\n",
      "CV scores: -0.0564154411765 [-0.03125    -0.0390625  -0.08235294 -0.0627451  -0.06666667]\n",
      "best params {'C': 10, 'fit_intercept': False}\n",
      "#######\n",
      "at loop: 4 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.056393995098 [-0.03515625 -0.0625     -0.05098039 -0.07058824 -0.0627451 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 5 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0547947303922 [-0.07421875 -0.0625     -0.04313725 -0.04705882 -0.04705882]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 6 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0548468137255 [-0.02734375 -0.04296875 -0.08627451 -0.04313725 -0.0745098 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 7 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0555943627451 [-0.05078125 -0.06640625 -0.05490196 -0.04313725 -0.0627451 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 8 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0555943627451 [-0.05078125 -0.06640625 -0.05098039 -0.03529412 -0.0745098 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 9 for outcome  layoff\n",
      "score: 0.039684323691\n",
      "CV scores: -0.0571691176471 [-0.04296875 -0.06640625 -0.05098039 -0.05882353 -0.06666667]\n",
      "best params {'C': 10, 'fit_intercept': False}\n",
      "#######\n",
      "at loop: 10 for outcome  layoff\n",
      "score: 0.0395700665593\n",
      "CV scores: -0.0563786764706 [-0.0703125  -0.046875   -0.04313725 -0.05882353 -0.0627451 ]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 1 for outcome  jobTraining\n",
      "best so far\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.120436766241 [-0.11604096 -0.11945392 -0.14675768 -0.12371134 -0.09621993]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 2 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.119772937851 [-0.10580205 -0.13651877 -0.12286689 -0.10652921 -0.12714777]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 3 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.122517387378 [-0.12969283 -0.09556314 -0.14334471 -0.14776632 -0.09621993]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 4 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.120469605808 [-0.12627986 -0.11262799 -0.11945392 -0.11683849 -0.12714777]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 5 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.120408618041 [-0.12627986 -0.12286689 -0.15358362 -0.11683849 -0.08247423]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 6 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.118412441505 [-0.10580205 -0.12286689 -0.12627986 -0.13745704 -0.09965636]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 7 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.121114668731 [-0.15017065 -0.12286689 -0.11604096 -0.10309278 -0.11340206]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 8 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.120497754008 [-0.10580205 -0.10580205 -0.12627986 -0.13402062 -0.13058419]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n",
      "at loop: 9 for outcome  jobTraining\n",
      "score: 0.0864428614661\n",
      "CV scores: -0.120521210842 [-0.10238908 -0.11262799 -0.10580205 -0.12714777 -0.15463918]\n",
      "best params {'C': 10, 'fit_intercept': False}\n",
      "#######\n",
      "at loop: 10 for outcome  jobTraining\n",
      "score: 0.0864061247502\n",
      "CV scores: -0.121119360098 [-0.12286689 -0.13651877 -0.12627986 -0.11340206 -0.10652921]\n",
      "best params {'C': 10, 'fit_intercept': True}\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "NUM_MODELS = 10\n",
    "n_CVjobs = 9\n",
    "n_CVsplits = 5\n",
    "n_modelJobs = 7 #*4 ##remove the comment on EC2\n",
    "mode = None\n",
    "n_iter_search = 30\n",
    "max_features = 18 ##this should be < n_features\n",
    "\n",
    "reg_outcomes = ['gpa', 'grit', 'materialHardship']\n",
    "clf_outcomes = [ 'eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__reg_param_dist = {\"fit_intercept\":[True,False], \"normalize\":[True,False]}\n",
    "\n",
    "__clf_param_dist = { \"C\":[0.001,0.00001,1.0,10], \"fit_intercept\":[True,False]}\n",
    "\n",
    "\n",
    "###### We don't use this anymore (where we average the parameters of the model)####\n",
    "#__reg_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'oob_score':[]}\n",
    "#\n",
    "#__clf_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'criterion':[]}\n",
    "#best_param = {'reg' : __reg_param,\n",
    "#              'clf': __clf_param}\n",
    "\n",
    "param_dist = {'reg' : __reg_param_dist,\n",
    "              'clf': __clf_param_dist}\n",
    "\n",
    "model = {'reg' : LinearRegression(),\n",
    "          'clf': LogisticRegression()}\n",
    "\n",
    "scorer = {'reg' : make_scorer(mean_squared_error,greater_is_better=False),\n",
    "           'clf' : make_scorer(brier_score_loss,greater_is_better=False)}\n",
    "\n",
    "evaluate_error = {'reg': mean_squared_error,\n",
    "                  'clf': brier_score_loss}\n",
    "\n",
    "\n",
    "best_model_prediction = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,\n",
    "               'grit':None,\n",
    "               'materialHardship':None,\n",
    "               'eviction':None,\n",
    "               'layoff': None,\n",
    "               'jobTraining':None\n",
    "              }\n",
    "\n",
    "avg_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "weighted_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "\n",
    "\n",
    "\n",
    "for outcome in outcomes:\n",
    "    ##Figure out in what mode we are\n",
    "    if outcome in reg_outcomes:\n",
    "        mode = 'reg'\n",
    "    else:\n",
    "        mode = 'clf'\n",
    "    \n",
    "    ###prepare X and Y####\n",
    "    full = dfx.join(dfy, how='outer') #connect the background data to outcomes\n",
    "    full_X = full.copy()\n",
    "    for inner_outcome in outcomes:\n",
    "        del full[inner_outcome]\n",
    "    X = full_X.dropna(subset=[outcome], how='all')\n",
    "    y = X[outcome]\n",
    "    for inner_outcome in outcomes:\n",
    "        del full_X[inner_outcome]\n",
    "\n",
    "    for inner_outcome in outcomes:\n",
    "        del X[inner_outcome]\n",
    "        \n",
    "    ##In order to try the different aggregation mechanisms\n",
    "    combined_model_prediction = {'challengeID':np.array(list(dfx.index)),outcome: None}\n",
    "    lowest_error = np.inf\n",
    "    best_model = None\n",
    "    all_models_scores = []\n",
    "    weighted_models = [] \n",
    "    n_good_models = 0\n",
    "\n",
    "    for i in range(1,NUM_MODELS+1):\n",
    "        print('at loop:',i,'for outcome ', outcome)\n",
    "        ##prepare the nested CV\n",
    "        inner_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "\n",
    "        ########Nested CV with parameter optimization########\n",
    "        #the Randomized search for the best parameters through cross validation\n",
    "        search = GridSearchCV(estimator=model[mode], param_grid=param_dist[mode],\n",
    "                                    scoring = scorer[mode],\n",
    "                                    cv=inner_cv,n_jobs=n_CVjobs)\n",
    "        search.fit(X, y)\n",
    "        #The evaluation of the best model found by the inner CV by having an outer CV\n",
    "        nested_score = cross_val_score(search, X=X, y=y, cv=outer_cv)\n",
    "        if mode == 'reg':\n",
    "            prediction = search.best_estimator_.predict(X)\n",
    "        else:\n",
    "            prediction = search.best_estimator_.predict_proba(X)[:,1]\n",
    "\n",
    "        if evaluate_error[mode](y,prediction) < np.inf:\n",
    "            n_good_models +=1\n",
    "\n",
    "            if evaluate_error[mode](y,prediction) < lowest_error:\n",
    "                print('best so far')\n",
    "                lowest_error = evaluate_error[mode](y,prediction)\n",
    "                best_model = search.best_estimator_\n",
    "\n",
    "            if i == 1:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "            else:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome] + search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome]+ search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "\n",
    "                \n",
    "\n",
    "            all_models_scores.append(evaluate_error[mode](y,prediction))\n",
    "            if mode == 'reg':\n",
    "                weighted_models.append(search.best_estimator_.predict(full_X))\n",
    "            else:\n",
    "                weighted_models.append(search.best_estimator_.predict_proba(full_X)[:,1])\n",
    "        print('score:', evaluate_error[mode](y,prediction))\n",
    "        print('CV scores:', nested_score.mean(), nested_score)\n",
    "        print('best params', search.best_params_)\n",
    "        print('#######')\n",
    "    \n",
    "\n",
    "        \n",
    "        ##best model prediction\n",
    "        best_model.fit(X, y)\n",
    "        if mode == 'reg':\n",
    "            final_prediction = best_model.predict(full_X)\n",
    "        else:\n",
    "            final_prediction = best_model.predict_proba(full_X)[:,1]\n",
    "        best_model_prediction[outcome] = final_prediction\n",
    "        \n",
    "        ##avg models prediction\n",
    "        avg_models_prediction[outcome] = combined_model_prediction[outcome]/float(n_good_models)\n",
    "        \n",
    "        \n",
    "        ##weighted models prediction\n",
    "        scores = np.array(all_models_scores)\n",
    "        normlized_scores = scores/sum(scores)\n",
    "        normlized_scores = normlized_scores.reshape(normlized_scores.shape[0],1)\n",
    "        models_predicitons = np.matrix(weighted_models).T\n",
    "        weighted_prediction = np.array(models_predicitons*normlized_scores).flatten().tolist()\n",
    "        weighted_models_prediction[outcome] = weighted_prediction\n",
    "\n",
    "df_best = pd.DataFrame.from_dict(best_model_prediction)\n",
    "df_avg = pd.DataFrame.from_dict(avg_models_prediction)\n",
    "df_weighted = pd.DataFrame.from_dict(weighted_models_prediction)\n",
    "\n",
    "df_best.to_csv('../output/final_pred/LR_prediction.csv')\n",
    "#df_avg.to_csv('./Linear_avg_prediction.csv',index=False)\n",
    "#df_weighted.to_csv('./Linear_weighted_prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ensemble (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at loop: 1 for outcome  gpa\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bde4ed6a72b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#The evaluation of the best model found by the inner CV by having an outer CV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielrigobon/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_MODELS = 10\n",
    "n_CVjobs = -1\n",
    "n_CVsplits = 5\n",
    "n_modelJobs = -1 #*4 ##remove the comment on EC2\n",
    "mode = None\n",
    "n_iter_search = 30\n",
    "max_features = 15 ##this should be the number of features / 5\n",
    "\n",
    "reg_outcomes = ['gpa', 'grit', 'materialHardship']\n",
    "clf_outcomes = [ 'eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__reg_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'oob_score':[True,False]}\n",
    "\n",
    "__clf_param_dist = {'max_depth': [1,2,3,4,None],\n",
    "                    'max_features': randint(1, max_features),\n",
    "                    'min_samples_split':randint(2, 300),\n",
    "                    'min_samples_leaf':randint(1, 300),\n",
    "                    'n_estimators':randint(50, 500),\n",
    "                    'criterion':['gini','entropy']}\n",
    "\n",
    "\n",
    "###### We don't use this anymore (where we average the parameters of the model)####\n",
    "#__reg_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'oob_score':[]}\n",
    "#\n",
    "#__clf_param = {'max_depth': [],\n",
    "#               'max_features': [],\n",
    "#               'min_samples_split':[],\n",
    "#               'min_samples_leaf':[],\n",
    "#               'n_estimators':[],\n",
    "#               'criterion':[]}\n",
    "#best_param = {'reg' : __reg_param,\n",
    "#              'clf': __clf_param}\n",
    "\n",
    "param_dist = {'reg' : __reg_param_dist,\n",
    "              'clf': __clf_param_dist}\n",
    "\n",
    "model = {'reg' : RandomForestRegressor(n_jobs=n_modelJobs),\n",
    "          'clf': RandomForestClassifier(n_jobs=n_modelJobs)}\n",
    "\n",
    "scorer = {'reg' : make_scorer(mean_squared_error,greater_is_better=False),\n",
    "           'clf' : make_scorer(brier_score_loss,greater_is_better=False)}\n",
    "\n",
    "evaluate_error = {'reg': mean_squared_error,\n",
    "                  'clf': brier_score_loss}\n",
    "\n",
    "\n",
    "best_model_prediction = {'challengeID':np.array(list(dfx.index)),\n",
    "               'gpa':None,\n",
    "               'grit':None,\n",
    "               'materialHardship':None,\n",
    "               'eviction':None,\n",
    "               'layoff': None,\n",
    "               'jobTraining':None\n",
    "              }\n",
    "\n",
    "avg_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "weighted_models_prediction = copy.deepcopy(best_model_prediction)\n",
    "\n",
    "\n",
    "for outcome in outcomes:\n",
    "    ##Figure out in what mode we are\n",
    "    if outcome in reg_outcomes:\n",
    "        mode = 'reg'\n",
    "    else:\n",
    "        mode = 'clf'\n",
    "    \n",
    "    ###prepare X and Y####\n",
    "    full = dfx.join(dfy, how='outer') #connect the background data to outcomes\n",
    "    full_X = full.copy()\n",
    "    for inner_outcome in outcomes:\n",
    "        del full[inner_outcome]\n",
    "    X = full_X.dropna(subset=[outcome], how='all')\n",
    "    y = X[outcome]\n",
    "    for inner_outcome in outcomes:\n",
    "        del full_X[inner_outcome]\n",
    "\n",
    "    for inner_outcome in outcomes:\n",
    "        del X[inner_outcome]\n",
    "        \n",
    "    ##In order to try the different aggregation mechanisms\n",
    "    combined_model_prediction = {'challengeID':np.array(list(dfx.index)),outcome: None}\n",
    "    lowest_error = np.inf\n",
    "    best_model = None\n",
    "    all_models_scores = []\n",
    "    weighted_models = [] \n",
    "    n_good_models = 0\n",
    "\n",
    "    for i in range(1,NUM_MODELS+1):\n",
    "        print('at loop:',i,'for outcome ', outcome)\n",
    "        ##prepare the nested CV\n",
    "        inner_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_CVsplits, shuffle=True, random_state=i)\n",
    "\n",
    "        ########Nested CV with parameter optimization########\n",
    "        #the Randomized search for the best parameters through cross validation\n",
    "        search = RandomizedSearchCV(estimator=model[mode], param_distributions=param_dist[mode],\n",
    "                                    scoring = scorer[mode],\n",
    "                                    cv=inner_cv,n_jobs=n_CVjobs,n_iter=n_iter_search)\n",
    "        search.fit(X, y)\n",
    "        #The evaluation of the best model found by the inner CV by having an outer CV\n",
    "        nested_score = cross_val_score(search, X=X, y=y, cv=outer_cv)\n",
    "        if mode == 'reg':\n",
    "            prediction = search.best_estimator_.predict(X)\n",
    "        else:\n",
    "            prediction = search.best_estimator_.predict_proba(X)[:,1]\n",
    "\n",
    "        if evaluate_error[mode](y,prediction) < np.inf:\n",
    "            n_good_models +=1\n",
    "\n",
    "            if evaluate_error[mode](y,prediction) < lowest_error:\n",
    "                print('best so far')\n",
    "                lowest_error = evaluate_error[mode](y,prediction)\n",
    "                best_model = search.best_estimator_\n",
    "\n",
    "            if i == 1:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "            else:\n",
    "                if mode == 'reg':\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome] + search.best_estimator_.predict(full_X)\n",
    "                else:\n",
    "                    combined_model_prediction[outcome] = combined_model_prediction[outcome]+ search.best_estimator_.predict_proba(full_X)[:,1]\n",
    "\n",
    "                \n",
    "\n",
    "            all_models_scores.append(evaluate_error[mode](y,prediction))\n",
    "            if mode == 'reg':\n",
    "                weighted_models.append(search.best_estimator_.predict(full_X))\n",
    "            else:\n",
    "                weighted_models.append(search.best_estimator_.predict_proba(full_X)[:,1])\n",
    "        print('score:', evaluate_error[mode](y,prediction))\n",
    "        print('CV scores:', nested_score.mean(), nested_score)\n",
    "        print('best params', search.best_params_)\n",
    "        print('#######')\n",
    "    \n",
    "\n",
    "        \n",
    "        ##best model prediction\n",
    "        best_model.fit(X, y)\n",
    "        if mode == 'reg':\n",
    "            final_prediction = best_model.predict(full_X)\n",
    "        else:\n",
    "            final_prediction = best_model.predict_proba(full_X)[:,1]\n",
    "        best_model_prediction[outcome] = final_prediction\n",
    "        \n",
    "        ##avg models prediction\n",
    "        avg_models_prediction[outcome] = combined_model_prediction[outcome]/float(n_good_models)\n",
    "        \n",
    "        \n",
    "        ##weighted models prediction\n",
    "        scores = np.array(all_models_scores)\n",
    "        normlized_scores = scores/sum(scores)\n",
    "        normlized_scores = normlized_scores.reshape(normlized_scores.shape[0],1)\n",
    "        models_predicitons = np.matrix(weighted_models).T\n",
    "        weighted_prediction = np.array(models_predicitons*normlized_scores).flatten().tolist()\n",
    "        weighted_models_prediction[outcome] = weighted_prediction\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "df_best = pd.DataFrame.from_dict(best_model_prediction)\n",
    "df_avg = pd.DataFrame.from_dict(avg_models_prediction)\n",
    "df_weighted = pd.DataFrame.from_dict(weighted_models_prediction)\n",
    "\n",
    "df_best.to_csv('../output/final_pred/RF_prediction.csv')\n",
    "#df_avg.to_csv(output_file+'/avg_prediction/prediction.csv')\n",
    "#df_weighted.to_csv(output_file+'/weighted_prediction/prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
