{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Analyze results from Predictions Files created by Models\n",
    "# Inputs: Prediction files from Random Forest, Elastic Net, XGBoost, and Team Ensembles\n",
    "# Outputs: Figures (some included in the paper, some in SI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.stats as AS\n",
    "from scipy.stats.stats import pearsonr \n",
    "from os import listdir\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data, generating In-Sample Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dict = {'lassoRF_prediction': 'Lasso RF','elastic_prediction': 'Elastic Net','RF_prediction': 'Ensemble RF',\n",
    "          'LR_prediction': 'Ensemble LR','weighted_multiRF_prediction': 'Nested RF',\n",
    "          'weighted_avrg_prediction': 'Weighted Team Avg', 'avrg_prediction': 'Team Avg',\n",
    "          'xgboost_prediction': 'Gradient Boosted Tree'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training=pd.read_csv('../data/train.csv',index_col = 'challengeID')\n",
    "baseline=np.mean(training, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BL_CV_scores = pd.DataFrame(columns = ['outcome','type','model','score_avg'])\n",
    "\n",
    "for outcome in training.columns.values:\n",
    "        y = training[outcome].dropna()\n",
    "        y_hat = baseline[outcome]\n",
    "        partition_scores = list()\n",
    "\n",
    "        for i in range(10,110,10):\n",
    "            bools = y.index<np.percentile(y.index,i)\n",
    "            y_curr=y[bools]\n",
    "            partition_scores.append(np.linalg.norm(y_curr-y_hat)/len(y_curr))\n",
    "\n",
    "        bootstrapped_means = AS.bootstrap(np.array(partition_scores),samples = 10, bootnum = 100, bootfunc = np.mean)\n",
    "        to_add = pd.DataFrame({'outcome':list(len(bootstrapped_means)*[outcome]),'type':len(bootstrapped_means)*['In-Sample Error'],'model':len(bootstrapped_means)*['Baseline'],'score_avg':bootstrapped_means})\n",
    "\n",
    "        BL_CV_scores = BL_CV_scores.append(to_add, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bootstrapped_scores_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in list(name_dict.keys()):\n",
    "    model_name = name_dict[name]\n",
    "    \n",
    "    data=pd.read_csv(str('../output/final_pred/'+name+'.csv'), index_col = 'challengeID')\n",
    "\n",
    "    CV_scores = pd.DataFrame(columns = ['outcome','type','model','score_avg'])\n",
    "    for outcome in training.columns.values:\n",
    "        y = training[outcome].dropna()\n",
    "        y_hat = data[outcome][np.in1d(data.index,y.index)]    \n",
    "        partition_scores = list()\n",
    "\n",
    "        for i in range(10,110,10):\n",
    "            bools = y.index<np.percentile(y.index,i)\n",
    "            y_curr=y[bools]\n",
    "            y_hat_curr = y_hat[bools]\n",
    "            partition_scores.append(np.linalg.norm(y_curr-y_hat_curr)/len(y_curr))\n",
    "\n",
    "        bootstrapped_means = AS.bootstrap(np.array(partition_scores),samples = 10, bootnum = 100, bootfunc = np.mean)\n",
    "        \n",
    "        bootstrapped_means = (1-np.divide(bootstrapped_means,BL_CV_scores.score_avg[BL_CV_scores.outcome==outcome]))*100\n",
    "        to_add = pd.DataFrame({'outcome':list(len(bootstrapped_means)*[outcome]),'type':len(bootstrapped_means)*['In-Sample Error'],'model':len(bootstrapped_means)*[model_name],'score_avg':bootstrapped_means})\n",
    "\n",
    "        CV_scores = CV_scores.append(to_add, ignore_index = True)\n",
    "    bootstrapped_scores_all[name] = CV_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBT_CV = bootstrapped_scores_all['xgboost_prediction']\n",
    "GBT_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Gradient Boosted Tree'],'score_avg':[0.37543,0.22008,0.02437,0.05453,0.17406,0.19676]})\n",
    "GBT_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Gradient Boosted Tree'],'score_avg':[0.34379983,0.238180899,0.019950074,0.056877623,0.167392429,0.177202581]})\n",
    "GBT_scores = GBT_CV.append(GBT_leaderboard.append(GBT_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "avrg_CV = bootstrapped_scores_all['avrg_prediction']\n",
    "avrg_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Team Avg'],'score_avg':[0.36587,0.21287,0.02313,0.05025,0.17467,0.20058]})\n",
    "avrg_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Team Avg'],'score_avg':[0.352115776,0.241462042,0.019888218,0.053480264,0.169287396,0.181767792]})\n",
    "avrg_scores = avrg_CV.append(avrg_leaderboard.append(avrg_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "weighted_avrg_CV = bootstrapped_scores_all['weighted_avrg_prediction']\n",
    "weighted_avrg_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Weighted Team Avg'],'score_avg':[0.36587,0.21287,0.02301,0.04917,0.1696,0.19782]})\n",
    "weighted_avrg_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Weighted Team Avg'],'score_avg':[0.352115776,0.241462042,0.020189616,0.053818827,0.162462938,0.178098036]})\n",
    "weighted_avrg_scores = weighted_avrg_CV.append(weighted_avrg_leaderboard.append(weighted_avrg_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "multi_RF_CV = bootstrapped_scores_all['weighted_multiRF_prediction']\n",
    "multi_RF_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Nested RF'],'score_avg':[0.38766,0.22353,0.02542,0.05446,0.20228,0.22092]})\n",
    "multi_RF_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Nested RF'],'score_avg':[0.365114483,0.248124154,0.021174361,0.063930882,0.207400541,0.191352482]})\n",
    "multi_RF_scores = multi_RF_CV.append(multi_RF_leaderboard.append(multi_RF_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "LR_CV = bootstrapped_scores_all['LR_prediction']\n",
    "LR_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Ensemble LR'],'score_avg':[0.37674,0.2244,0.02715,0.05092,0.18341,0.22311]})\n",
    "LR_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Ensemble LR'],'score_avg':[0.364780108,0.247382526,0.021359837,0.058200047,0.181441591,0.194502527]})\n",
    "LR_scores = LR_CV.append(LR_leaderboard.append(LR_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "RF_CV = bootstrapped_scores_all['RF_prediction']\n",
    "RF_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Ensemble RF'],'score_avg':[0.38615,0.22342,0.02547,0.05475,0.20346,0.22135]})\n",
    "RF_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Ensemble RF'],'score_avg':[0.364609923,0.247940405,0.021135379,0.064494339,0.208869867,0.191742726]})\n",
    "RF_scores = RF_CV.append(RF_leaderboard.append(RF_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "lasso_RF_CV = bootstrapped_scores_all['lassoRF_prediction']\n",
    "lasso_RF_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Lasso RF'],'score_avg':[0.37483,0.21686,0.02519,0.05226,0.17223,0.20028]})\n",
    "lasso_RF_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Lasso RF'],'score_avg':[0.361450643,0.243745261,0.020491841,0.054397319,0.165154165,0.180446409]})\n",
    "lasso_scores = lasso_RF_CV.append(lasso_RF_leaderboard.append(lasso_RF_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "eNet_CV = bootstrapped_scores_all['elastic_prediction']\n",
    "eNet_leaderboard = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Elastic Net'],'score_avg':[0.36477,0.21252,0.02353,0.05341,0.17435,0.20224]})\n",
    "eNet_holdout = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Elastic Net'],'score_avg':[0.350083,0.239361,0.019791,0.055458,0.167224,0.185329]})\n",
    "eNet_scores = eNet_CV.append(eNet_leaderboard.append(eNet_holdout,ignore_index = True),ignore_index = True)\n",
    "\n",
    "#bools = np.in1d(eNet_scores.outcome,['gpa','grit','materialHardship'])\n",
    "#eNet_scores = eNet_scores.loc[bools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Score Aggregation and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Baseline Scores:\n",
    "BL_LB = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Leaderboard'],'model':6*['Baseline'],'score_avg':[0.39273,0.21997,0.02880,0.05341,0.17435,0.20224]})\n",
    "BL_HO = pd.DataFrame({'outcome':['gpa','grit','materialHardship','eviction','layoff','jobTraining'],'type':6*['Holdout'],'model':6*['Baseline'],'score_avg':[0.425148881,0.252983596,0.024905617,0.055457913,0.167223718,0.185329492]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_all = eNet_scores.append(lasso_scores.append(RF_scores.append(LR_scores.append(multi_RF_scores.append(weighted_avrg_scores.append(avrg_scores.append(GBT_scores,ignore_index = True),ignore_index = True),ignore_index = True),ignore_index = True),ignore_index = True),ignore_index = True), ignore_index = True)\n",
    "scores_ADJ = scores_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = scores_all.loc[scores_all.type != 'In-Sample Error']\n",
    "for OUTCOME in training.columns.values:\n",
    "    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 7), sharex=True)\n",
    "\n",
    "    temp=scores.loc[scores.outcome==OUTCOME]\n",
    "    temp.score_avg.loc[temp.type=='Leaderboard']=(1-np.divide(temp.score_avg.loc[temp.type=='Leaderboard'],BL_LB.score_avg.loc[BL_LB.outcome==OUTCOME]))*100\n",
    "    temp.score_avg.loc[temp.type=='Holdout']=(1-np.divide(temp.score_avg.loc[temp.type=='Holdout'],BL_HO.score_avg.loc[BL_HO.outcome==OUTCOME]))*100\n",
    "    \n",
    "    \n",
    "    scores_ADJ.score_avg.loc[(scores_ADJ.outcome==OUTCOME) & (scores_ADJ.type=='Leaderboard')] = (1-np.divide(scores_ADJ.score_avg.loc[(scores_ADJ.outcome==OUTCOME) & (scores_ADJ.type=='Leaderboard')],BL_LB.score_avg.loc[BL_LB.outcome==OUTCOME]))*100\n",
    "    scores_ADJ.score_avg.loc[(scores_ADJ.outcome==OUTCOME) & (scores_ADJ.type=='Holdout')] = (1-np.divide(scores_ADJ.score_avg.loc[(scores_ADJ.outcome==OUTCOME) & (scores_ADJ.type=='Holdout')],BL_HO.score_avg.loc[BL_HO.outcome==OUTCOME]))*100\n",
    "\n",
    "    \n",
    "    \n",
    "    sns.barplot('model','score_avg',hue = 'type', data = temp, ci = 'sd', ax=ax)\n",
    "\n",
    "    ax.set_title(str(OUTCOME))\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Accuracy Improvement over Baseline (%)')\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.savefig(str('../output/fig/'+OUTCOME+'.pdf'))\n",
    "    bools_L = (scores.type=='Leaderboard') & (scores.outcome==OUTCOME)\n",
    "    bools_H = (scores.type=='Holdout') & (scores.outcome==OUTCOME)\n",
    "    print(OUTCOME)\n",
    "    print('Best Leaderboard Model: ',scores.loc[(bools_L)&(scores.loc[bools_L].score_avg==max(scores.loc[bools_L].score_avg))].model)\n",
    "    print('Best Holdout Model: ',scores.loc[(bools_H)&(scores.loc[bools_H].score_avg==max(scores.loc[bools_H].score_avg))].model)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = scores_all.loc[scores_all.type=='In-Sample Error']\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 7), sharex=True)\n",
    "    \n",
    "sns.barplot('model','score_avg', hue = 'outcome', data = scores, ci = 'sd', ax=ax)\n",
    "\n",
    "ax.set_title('In-Sample Model Performance Improvement')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Accuracy Improvement over Baseline (%)')\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "plt.ylim([-20,100])\n",
    "ax.tick_params(labelsize=18)\n",
    "plt.savefig(str('../output/fig/ALL_IS.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = scores_all.loc[scores_all.type=='In-Sample Error']\n",
    "for OUTCOME in training.columns.values:\n",
    "    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 7), sharex=True)\n",
    "\n",
    "    temp=scores.loc[scores.outcome==OUTCOME]\n",
    "    \n",
    "    sns.barplot('model','score_avg', data = temp, ci = 'sd', ax=ax, color = 'red')\n",
    "\n",
    "    ax.set_title(str(OUTCOME))\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Accuracy Improvement over Baseline (%)')\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.savefig(str('../output/fig/'+OUTCOME+'_IS.pdf'))\n",
    "    bools_L = (scores.type=='Leaderboard') & (scores.outcome==OUTCOME)\n",
    "    bools_H = (scores.type=='Holdout') & (scores.outcome==OUTCOME)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partition Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_PLT = scores_ADJ\n",
    "\n",
    "scores_PLT = scores_PLT.loc[~((scores_ADJ.model=='Elastic Net') & np.in1d(scores_ADJ.outcome,['eviction','layoff','jobTraining']))]\n",
    "scores_PLT['color'] = [-1]*np.shape(scores_PLT)[0]\n",
    "\n",
    "for i,OUTCOME in enumerate(['gpa', 'grit', 'materialHardship', 'eviction', 'layoff', 'jobTraining']):\n",
    "    scores_PLT.color.loc[scores_PLT.outcome==OUTCOME] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEADERBOARD vs HOLDOUT\n",
    "\n",
    "\n",
    "scores_X = scores_PLT.loc[scores_PLT.type=='Leaderboard']\n",
    "scores_Y = scores_PLT.loc[scores_PLT.type=='Holdout']  \n",
    "\n",
    "txt = [str(a) for a,b in zip(scores_X.model,scores_X.outcome)]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 12), sharex=True)\n",
    "colors = ['red','blue','green','black','yellow','orange']\n",
    "for i in range(6):\n",
    "    corr_temp = np.round(pearsonr(scores_X.score_avg.loc[scores_X.color==i],\n",
    "                                  scores_Y.score_avg.loc[scores_Y.color==i]),decimals = 3)\n",
    "    plt.scatter(x = scores_X.score_avg.loc[scores_X.color==i], \n",
    "                s=20, y = scores_Y.score_avg.loc[scores_Y.color==i],\n",
    "                c = colors[i],label=str(scores_X.outcome.loc[scores_X.color==i].iloc[0])+': r^2='+str(corr_temp[0])+' p='+str(corr_temp[1]))     \n",
    "    print(i)\n",
    "    print(len(scores_X.score_avg.loc[scores_X.color==i]),\n",
    "          len(scores_Y.score_avg.loc[scores_Y.color==i]))\n",
    "ax.set_xlabel('Leaderboard Improvement Over Baseline (%)')\n",
    "ax.set_ylabel('Holdout Improvement Over Baseline (%)')\n",
    "ax.tick_params(labelsize=18)\n",
    "plt.ylim([-26, 22])\n",
    "plt.xlim([-26, 22])\n",
    "ax.plot([-26,22],[-26,22], 'k-')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "for i,n in enumerate(txt):\n",
    "    ax.annotate(n,(scores_X.score_avg.iloc[i],scores_Y.score_avg.iloc[i]),\n",
    "                size = 10,textcoords='data')\n",
    "\n",
    "plt.savefig(str('../output/fig/LB_vs_HO.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEADERBOARD VS IN-SAMPLE\n",
    "\n",
    "\n",
    "scores_X = scores_PLT.loc[scores_PLT.type=='Leaderboard']\n",
    "scores_Y = scores_PLT.loc[scores_PLT.type=='In-Sample Error']  \n",
    "scores_Y = pd.DataFrame(scores_Y.groupby([scores_Y.model,scores_Y.outcome]).mean())\n",
    "\n",
    "\n",
    "txt = [str(a) for a,b in zip(scores_X.model,scores_X.outcome)]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 12), sharex=True)\n",
    "colors = ['red','blue','green','black','yellow','orange']\n",
    "for i in range(6):\n",
    "    corr_temp = np.round(pearsonr(scores_X.score_avg.loc[scores_X.color==i],\n",
    "                                  scores_Y.score_avg.loc[scores_Y.color==i]),decimals = 3)\n",
    "    plt.scatter(x = scores_X.score_avg.loc[scores_X.color==i], \n",
    "                s=20, y = scores_Y.score_avg.loc[scores_Y.color==i],\n",
    "                c = colors[i],label=str(scores_X.outcome.loc[scores_X.color==i].iloc[0])+': r^2='+str(corr_temp[0])+' p='+str(corr_temp[1]))     \n",
    "    print(i)\n",
    "    print(len(scores_X.score_avg.loc[scores_X.color==i]),\n",
    "          len(scores_Y.score_avg.loc[scores_Y.color==i]))\n",
    "ax.set_xlabel('Leaderboard Improvement Over Baseline (%)')\n",
    "ax.set_ylabel('In-Sample Error Improvement Over Baseline (%)')\n",
    "ax.tick_params(labelsize=18)\n",
    "#plt.ylim([-26, 22])\n",
    "#plt.xlim([-26, 22])\n",
    "#ax.plot([-26,22],[-26,22], 'k-')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "for i,n in enumerate(txt):\n",
    "    ax.annotate(n,(scores_X.score_avg.iloc[i],scores_Y.score_avg.iloc[i]),\n",
    "                size = 10,textcoords='data')\n",
    "\n",
    "plt.savefig(str('../output/fig/LB_vs_IS.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HOLDOUT VS IN-SAMPLE\n",
    "\n",
    "\n",
    "scores_X = scores_PLT.loc[scores_PLT.type=='Holdout']\n",
    "scores_Y = scores_PLT.loc[scores_PLT.type=='In-Sample Error']  \n",
    "scores_Y = scores_Y.groupby([scores_Y.model,scores_Y.outcome]).mean().reset_index()\n",
    "# UNCOMMENT if STD\n",
    "#scores_Y.color = [0, 1, 2, 3, 0, 1, 5, 4, 2, 3, 0, 1, 5, 4, 2, 3, 0, 1, 5, 4, 2, 3, 0,\n",
    "#       1, 5, 4, 2, 3, 0, 1, 5, 4, 2, 3, 0, 1, 5, 4, 2, 3, 0, 1, 5, 4, 2]\n",
    "\n",
    "txt = [str(a) for a,b in zip(scores_X.model,scores_X.outcome)]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 12), sharex=True)\n",
    "colors = ['red','blue','green','black','yellow','orange']\n",
    "for i in range(6):\n",
    "    corr_temp = np.round(pearsonr(scores_X.score_avg.loc[scores_X.color==i],\n",
    "                                  scores_Y.score_avg.loc[scores_Y.color==i]),decimals = 3)\n",
    "    plt.scatter(x = scores_X.score_avg.loc[scores_X.color==i], \n",
    "                s=20, y = scores_Y.score_avg.loc[scores_Y.color==i],\n",
    "                c = colors[i],label=str(scores_X.outcome.loc[scores_X.color==i].iloc[0])+': r^2='+str(corr_temp[0])+' p='+str(corr_temp[1]))     \n",
    "    print(i)\n",
    "    print(len(scores_X.score_avg.loc[scores_X.color==i]),\n",
    "          len(scores_Y.score_avg.loc[scores_Y.color==i]))\n",
    "ax.set_xlabel('Holdout Improvement Over Baseline (%)')\n",
    "ax.set_ylabel('In-Sample Error Improvement Over Baseline (%)')\n",
    "ax.tick_params(labelsize=18)\n",
    "#plt.ylim([-26, 22])\n",
    "#plt.xlim([-26, 22])\n",
    "#ax.plot([-26,22],[-26,22], 'k-')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "for i,n in enumerate(txt):\n",
    "    ax.annotate(n,(scores_X.score_avg.iloc[i],scores_Y.score_avg.iloc[i]),\n",
    "                size = 10,textcoords='data')\n",
    "\n",
    "plt.savefig(str('../output/fig/HO_vs_IS.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping Correlation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bootnum = 10000\n",
    "\n",
    "all_keys_boot = ['gpa']*bootnum\n",
    "temp = ['grit']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['materialHardship']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['eviction']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['layoff']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['jobTraining']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['overall']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "\n",
    "scores_ADJ = scores_all\n",
    "\n",
    "keys = ['gpa', 'grit', 'materialHardship', 'eviction', 'layoff', 'jobTraining','overall']\n",
    "\n",
    "\n",
    "t1 = ['In-Sample Error']*14\n",
    "temp = ['Leaderboard']*7\n",
    "t1.extend(temp)\n",
    "t2 = ['Leaderboard']*7\n",
    "temp = ['Holdout']*14\n",
    "t2.extend(temp)\n",
    "\n",
    "all_keys_boot = ['gpa']*bootnum\n",
    "temp = ['grit']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['materialHardship']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['eviction']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['layoff']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['jobTraining']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "temp = ['overall']*bootnum\n",
    "all_keys_boot.extend(temp)\n",
    "\n",
    "df_full = pd.DataFrame(columns = ['T1-T2', 'condition', 'avg_corr','sd_corr'])\n",
    "\n",
    "\n",
    "for [T1,T2] in [['In-Sample Error','Leaderboard'],['In-Sample Error','Holdout'],['Leaderboard','Holdout']]:\n",
    "\n",
    "    X_type = scores_ADJ.loc[scores_ADJ.type==T1]\n",
    "    Y_type = scores_ADJ.loc[scores_ADJ.type==T2]\n",
    "\n",
    "    avg_corr = list([])\n",
    "\n",
    "    # For Ind. Outcomes\n",
    "    for OUTCOME in ['gpa', 'grit', 'materialHardship', 'eviction', 'layoff', 'jobTraining']:\n",
    "        corr = np.zeros(bootnum)\n",
    "\n",
    "        X_OC = X_type.loc[X_type.outcome==OUTCOME]\n",
    "        Y_OC = Y_type.loc[Y_type.outcome==OUTCOME]\n",
    "\n",
    "        X_curr = X_OC.groupby(X_OC.model).score_avg.mean()\n",
    "        Y_curr = Y_OC.groupby(Y_OC.model).score_avg.mean()\n",
    "\n",
    "\n",
    "        for i in range(bootnum):\n",
    "            index = np.random.choice(list(range(len(X_curr))),len(X_curr))\n",
    "            avg_corr.append(pearsonr(X_curr[index].values,Y_curr[index].values)[0])\n",
    "\n",
    "    # For Overall\n",
    "    X_curr = X_type.groupby([X_type.model,X_type.outcome]).score_avg.mean()\n",
    "    Y_curr = Y_type.groupby([Y_type.model,Y_type.outcome]).score_avg.mean()\n",
    "    corr = np.zeros(bootnum)\n",
    "\n",
    "    for i in range(bootnum):\n",
    "        index = np.random.choice(list(range(len(X_curr))),len(X_curr))\n",
    "        avg_corr.append(pearsonr(X_curr[index].values,Y_curr[index].values)[0])\n",
    "\n",
    "    to_add = pd.DataFrame({'T1-T2':7*bootnum*[str(T1)+' w/ '+str(T2)], 'condition': all_keys_boot,\n",
    "                       'avg_corr':avg_corr})\n",
    "    \n",
    "    df_full = df_full.append(to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 7), sharex=True)\n",
    "    \n",
    "sns.barplot('T1-T2','avg_corr', hue = 'condition', data = df_full, ci = 'sd', ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Comparison')\n",
    "ax.set_xlabel('Data Partitions Compared')\n",
    "ax.set_ylabel('Avg. Correlation')\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "plt.ylim([-1.3,1.2])\n",
    "ax.tick_params(labelsize=18)\n",
    "plt.savefig(str('../output/fig/Correlation_Comparison.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 7), sharex=True)\n",
    "    \n",
    "sns.barplot('T1-T2','avg_corr', hue = 'condition', data = df_full.loc[df_full.condition=='overall'], ci = 'sd', ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Comparison')\n",
    "ax.set_xlabel('Data Partitions Compared')\n",
    "ax.set_ylabel('Avg. Correlation')\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "plt.ylim([0,1])\n",
    "ax.tick_params(labelsize=18)\n",
    "plt.savefig(str('../output/fig/Correlations_Overall.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "father = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Father'],'score': [0.199531305,0.140893472,0.221546773,0.1923971,0.130434782,0.27181208]})\n",
    "\n",
    "homevisit = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Home Visit'],'score': [0.203213929,0.209621994,0.189125295,0.112949541,0.036789297,0.187919463]})\n",
    "\n",
    "child = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Child'],'score': [0.044861065,0.003436426,0.082404594,0.01572542,0.006688963,0.023489933]})\n",
    "\n",
    "kinder = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Kindergarden'],'score': [0.003347841,0.003436426,0.00810537,0.008432472,0.003344482,0.006711409]})\n",
    "\n",
    "mother = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Mother'],'score': [0.349849352,0.515463913,0.360351229,0.569032313,0.66889632,0.395973155]})\n",
    "\n",
    "other = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Other'],'score': [0.016069635,0.01718213,0.003377237,0.0097999,0.006688963,0.016778523]})\n",
    "\n",
    "care = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Caregiver'],'score': [0.085369937,0.048109966,0.10570753,0.060713797,0.140468227,0.080536912]})\n",
    "\n",
    "teacher = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Teacher'],'score': [0.087378641,0.058419244,0.023302938,0.02306395,0.006688963,0.016778524]})\n",
    "\n",
    "\n",
    "wav1 = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Wave 1'],'score': [0.109809175,0.048109966,0.101654846,0.317288843,0.046822742,0.104026846]})\n",
    "\n",
    "wav2 = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Wave 2'],'score': [0.126548378,0.085910654,0.125295507,0.122612698,0.117056855,0.073825504]})\n",
    "\n",
    "wav3 = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Wave 3'],'score': [0.189822567,0.206185568,0.173252278,0.162496011,0.143812707,0.271812079]})\n",
    "\n",
    "wav4 = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Wave 4'],'score': [0.172079012,0.230240552,0.205336034,0.166826199,0.217391305,0.241610739]})\n",
    "\n",
    "wav5 = pd.DataFrame({'outcome': ['gpa','eviction','grit','materialHardship','jobTraining','layoff'],\n",
    "          'characteristic': 6*['Wave 5'],'score': [0.388014734,0.422680407,0.380276931,0.214458269,0.471571907,0.302013422]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "who_df = pd.concat([mother,father,care,homevisit,child,teacher,kinder,other],ignore_index = True)\n",
    "when_df = pd.concat([wav1,wav2,wav3,wav4,wav5],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 5), sharex=True)\n",
    "\n",
    "sns.barplot('characteristic','score', hue = 'outcome', data = who_df,\n",
    "            ci = None,ax=ax)\n",
    "\n",
    "ax.set_ylabel('Feature Importance (Sum)')\n",
    "ax.tick_params(labelsize=13)\n",
    "ax.set_ylim(0,0.7)\n",
    "plt.savefig('../output/fig/Who_Feature_Importance.pdf')\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 5), sharex=True)\n",
    "\n",
    "sns.barplot('characteristic','score', hue = 'outcome', data = when_df,\n",
    "            ci = None,ax=ax)\n",
    "\n",
    "ax.set_ylabel('Feature Importance (Sum)')\n",
    "ax.tick_params(labelsize=13)\n",
    "ax.set_ylim(0,0.7)\n",
    "plt.savefig('../output/fig/When_Feature_Importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LASSO_files = listdir('../output/LASSO_ALL/')\n",
    "MI_files = ['data_univariate_feature_selection_5.csv','data_univariate_feature_selection_15.csv','data_univariate_feature_selection_50.csv','data_univariate_feature_selection_100.csv','data_univariate_feature_selection_200.csv','data_univariate_feature_selection_300.csv','data_univariate_feature_selection_500.csv','data_univariate_feature_selection_700.csv','data_univariate_feature_selection_1000.csv','data_univariate_feature_selection_1500.csv','data_univariate_feature_selection_2000.csv','data_univariate_feature_selection_3000.csv','data_univariate_feature_selection_4000.csv']\n",
    "\n",
    "msk = [i!='.DS_Store' for i in LASSO_files]\n",
    "LASSO_files = [i for i,j in zip(LASSO_files,msk) if j]\n",
    "LASSO_files = np.sort(LASSO_files)\n",
    "\n",
    "MI_file = MI_files[0]\n",
    "L_file = LASSO_files[0]\n",
    "\n",
    "perc_similar = np.zeros((len(LASSO_files),len(MI_files)))\n",
    "PC1_corr = np.zeros((len(LASSO_files),len(MI_files)))\n",
    "L_names = []\n",
    "MI_names = []\n",
    "\n",
    "for i,L_file in enumerate(LASSO_files):\n",
    "    temp_L = pd.read_csv(('../output/LASSO_ALL/'+L_file))\n",
    "    L_names.append(np.shape(temp_L.columns.values)[0])\n",
    "    L_PC = PCA(n_components=2).fit_transform(temp_L)\n",
    "\n",
    "    for j,MI_file in enumerate(MI_files):\n",
    "        temp_M = pd.read_csv(('../output/MI/'+MI_file))\n",
    "        MI_names.append(np.shape(temp_M.columns.values)[0])\n",
    "        MI_PC = PCA(n_components=2).fit_transform(temp_M)\n",
    "\n",
    "        PC1_corr[i,j] = pearsonr(L_PC[:,0],MI_PC[:,0])[0]\n",
    "        perc_similar[i,j]= sum(np.in1d(temp_L.columns.values,temp_M.columns.values))\n",
    "        \n",
    "        \n",
    "\n",
    "data_named = pd.DataFrame(perc_similar,index = L_names, columns = np.unique(MI_names))\n",
    "columns = data_named.columns.tolist()\n",
    "columns = columns[::-1]\n",
    "data_named = data_named[columns]\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15), sharex=True)\n",
    "sns.heatmap(data_named, annot = True)\n",
    "plt.savefig('../output/fig/feature_heatmap.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L_names = [str('r^2='+str(i)) for i in np.linspace(0.1,0.9,9)]\n",
    "MI_names = [str('K='+str(i)) for i in [5,15,50,100,200,300,500,700,1000,1500,2000,3000,4000]]\n",
    "data_PC = pd.DataFrame(PC1_corr,index = L_names, columns = MI_names)\n",
    "columns = data_named.columns.tolist()\n",
    "columns = columns[::-1]\n",
    "data_named = data_named[columns]\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15), sharex=True)\n",
    "sns.heatmap(data_PC, annot = True)\n",
    "plt.savefig('../output/fig/PC1_heatmap.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
