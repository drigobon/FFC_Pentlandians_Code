{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Perform Feature Selection using Mutual Information for several K-values, save the output\n",
    "# Inputs: Imputed Dataset w/added Homelessness Indicators\n",
    "# Outputs: Several Files named after the K-cutoff used for MI on each outcome of interest\n",
    "# Machine: Laptop, Runtime 8 hrs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.preprocessing import Imputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = pd.read_csv('../output/data_mean_imputed_Homeless_added.csv',index_col='challengeID')\n",
    "dfy = pd.read_csv('../data/train.csv',index_col='challengeID')\n",
    "\n",
    "outcomes = list(dfy.columns) #get the names of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = dfx.join(dfy, how='outer') #connect the background data to outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = full.dropna(subset=outcomes, how='all') ##drop observations that have None of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in [5,15,50,100,200,300,500,700,1000,1500,2000,3000,4000]:\n",
    "    ## Selecting top K in GPA\n",
    "    gpa_x = training.dropna(subset=['gpa'], how='all')\n",
    "    gpa_y = gpa_x['gpa']\n",
    "    for outcome in outcomes:\n",
    "        del gpa_x[outcome]\n",
    "\n",
    "    X_gpa = SelectKBest(mutual_info_regression, k=k).fit_transform(gpa_x, gpa_y)\n",
    "    \n",
    "    gpa_featuers = []\n",
    "    for col in X_gpa.T:\n",
    "        gpa_featuers.append(gpa_x.columns[(gpa_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "    \n",
    "    \n",
    "    ## Selecting top K in Grit\n",
    "    grit_x = training.dropna(subset=['grit'], how='all')\n",
    "    grit_y = grit_x['grit']\n",
    "    for outcome in outcomes:\n",
    "        del grit_x[outcome]\n",
    "\n",
    "\n",
    "    X_grit = SelectKBest(mutual_info_regression, k=k).fit_transform(grit_x, grit_y)\n",
    "\n",
    "    grit_featuers = []\n",
    "    for col in X_grit.T:\n",
    "        grit_featuers.append(grit_x.columns[(grit_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "           \n",
    "        \n",
    "    ## Selecting top K in MaterialHardship\n",
    "    materialHardship_x = training.dropna(subset=['materialHardship'], how='all')\n",
    "    materialHardship_y = materialHardship_x['materialHardship']\n",
    "    for outcome in outcomes:\n",
    "        del materialHardship_x[outcome]\n",
    "\n",
    "\n",
    "    X_materialHardship = SelectKBest(mutual_info_regression, k=k).fit_transform(materialHardship_x, materialHardship_y)\n",
    "\n",
    "    materialHardship_featuers = []\n",
    "    for col in X_materialHardship.T:\n",
    "        materialHardship_featuers.append(materialHardship_x.columns[(materialHardship_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "    \n",
    "    \n",
    "    ## Selecting top K in Eviction\n",
    "    eviction_x = training.dropna(subset=['eviction'], how='all')\n",
    "    eviction_y = eviction_x['eviction']\n",
    "    for outcome in outcomes:\n",
    "        del eviction_x[outcome]\n",
    "\n",
    "    X_eviction = SelectKBest(mutual_info_classif, k=k).fit_transform(eviction_x, eviction_y)\n",
    "\n",
    "    eviction_featuers = []\n",
    "    for col in X_eviction.T:\n",
    "        eviction_featuers.append(eviction_x.columns[(eviction_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "\n",
    "    \n",
    "    # Selecting top K in Layoff\n",
    "    layoff_x = training.dropna(subset=['layoff'], how='all')\n",
    "    layoff_y = layoff_x['layoff']\n",
    "    for outcome in outcomes:\n",
    "        del layoff_x[outcome]\n",
    "\n",
    "    X_layoff = SelectKBest(mutual_info_classif, k=k).fit_transform(layoff_x, layoff_y)\n",
    "\n",
    "    layoff_featuers = []\n",
    "    for col in X_layoff.T:\n",
    "        layoff_featuers.append(layoff_x.columns[(layoff_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "\n",
    "\n",
    "    # Selecting top K in JobTraining\n",
    "    jobTraining_x = training.dropna(subset=['jobTraining'], how='all')\n",
    "    jobTraining_y = jobTraining_x['jobTraining']\n",
    "    for outcome in outcomes:\n",
    "        del jobTraining_x[outcome]\n",
    "\n",
    "    X_jobTraining = SelectKBest(mutual_info_classif, k=k).fit_transform(jobTraining_x, jobTraining_y)\n",
    "\n",
    "\n",
    "    jobTraining_featuers = []\n",
    "    for col in X_jobTraining.T:\n",
    "        jobTraining_featuers.append(jobTraining_x.columns[(jobTraining_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "        \n",
    "    \n",
    "    # Combine Features\n",
    "    final_features = list(set(jobTraining_featuers+layoff_featuers+eviction_featuers+materialHardship_featuers+grit_featuers+gpa_featuers))\n",
    "    selected_df = full[final_features]\n",
    "    \n",
    "    # Save CSV\n",
    "    selected_df.to_csv('../output/MI/data_univariate_feature_selection_'+str(k)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
