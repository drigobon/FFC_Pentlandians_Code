{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Perform Feature Selection using Mutual Information for several K-values, save the output\n",
    "# Inputs: Imputed Dataset w/added Homelessness Indicators\n",
    "# Outputs: Several Files named after the K-cutoff used for MI on each outcome of interest\n",
    "# Machine: Laptop, Runtime 45mins x #of K-Values (1 K-Value takes ~45 minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used Packages\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.preprocessing import Imputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = pd.read_csv('../output/data_mean_imputed_Homeless_added.csv',index_col='challengeID')\n",
    "dfy = pd.read_csv('../data/train.csv',index_col='challengeID')\n",
    "\n",
    "outcomes = list(dfy.columns) #get the names of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4242, 24866)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpa', 'grit', 'materialHardship', 'eviction', 'layoff', 'jobTraining']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = dfx.join(dfy, how='outer') #connect the background data to outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = full.dropna(subset=outcomes, how='all') ##drop observations that have None of the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in [5,15,50,100,200,300,500,700,1000,1500,2000,3000,4000]:\n",
    "    ## Selecting top K in GPA\n",
    "    gpa_x = training.dropna(subset=['gpa'], how='all')\n",
    "    gpa_y = gpa_x['gpa']\n",
    "    for outcome in outcomes:\n",
    "        del gpa_x[outcome]\n",
    "\n",
    "    X_gpa = SelectKBest(mutual_info_regression, k=k).fit_transform(gpa_x, gpa_y)\n",
    "    \n",
    "    gpa_featuers = []\n",
    "    for col in X_gpa.T:\n",
    "        gpa_featuers.append(gpa_x.columns[(gpa_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "    \n",
    "    \n",
    "    ## Selecting top K in Grit\n",
    "    grit_x = training.dropna(subset=['grit'], how='all')\n",
    "    grit_y = grit_x['grit']\n",
    "    for outcome in outcomes:\n",
    "        del grit_x[outcome]\n",
    "\n",
    "\n",
    "    X_grit = SelectKBest(mutual_info_regression, k=k).fit_transform(grit_x, grit_y)\n",
    "\n",
    "    grit_featuers = []\n",
    "    for col in X_grit.T:\n",
    "        grit_featuers.append(grit_x.columns[(grit_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "           \n",
    "        \n",
    "    ## Selecting top K in MaterialHardship\n",
    "    materialHardship_x = training.dropna(subset=['materialHardship'], how='all')\n",
    "    materialHardship_y = materialHardship_x['materialHardship']\n",
    "    for outcome in outcomes:\n",
    "        del materialHardship_x[outcome]\n",
    "\n",
    "\n",
    "    X_materialHardship = SelectKBest(mutual_info_regression, k=k).fit_transform(materialHardship_x, materialHardship_y)\n",
    "\n",
    "    materialHardship_featuers = []\n",
    "    for col in X_materialHardship.T:\n",
    "        materialHardship_featuers.append(materialHardship_x.columns[(materialHardship_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "    \n",
    "    \n",
    "    ## Selecting top K in Eviction\n",
    "    eviction_x = training.dropna(subset=['eviction'], how='all')\n",
    "    eviction_y = eviction_x['eviction']\n",
    "    for outcome in outcomes:\n",
    "        del eviction_x[outcome]\n",
    "\n",
    "    X_eviction = SelectKBest(mutual_info_classif, k=k).fit_transform(eviction_x, eviction_y)\n",
    "\n",
    "    eviction_featuers = []\n",
    "    for col in X_eviction.T:\n",
    "        eviction_featuers.append(eviction_x.columns[(eviction_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "\n",
    "    \n",
    "    # Selecting top K in Layoff\n",
    "    layoff_x = training.dropna(subset=['layoff'], how='all')\n",
    "    layoff_y = layoff_x['layoff']\n",
    "    for outcome in outcomes:\n",
    "        del layoff_x[outcome]\n",
    "\n",
    "    X_layoff = SelectKBest(mutual_info_classif, k=k).fit_transform(layoff_x, layoff_y)\n",
    "\n",
    "    layoff_featuers = []\n",
    "    for col in X_layoff.T:\n",
    "        layoff_featuers.append(layoff_x.columns[(layoff_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "\n",
    "\n",
    "    # Selecting top K in JobTraining\n",
    "    jobTraining_x = training.dropna(subset=['jobTraining'], how='all')\n",
    "    jobTraining_y = jobTraining_x['jobTraining']\n",
    "    for outcome in outcomes:\n",
    "        del jobTraining_x[outcome]\n",
    "\n",
    "    X_jobTraining = SelectKBest(mutual_info_classif, k=k).fit_transform(jobTraining_x, jobTraining_y)\n",
    "\n",
    "\n",
    "    jobTraining_featuers = []\n",
    "    for col in X_jobTraining.T:\n",
    "        jobTraining_featuers.append(jobTraining_x.columns[(jobTraining_x.values == np.asarray(col)[:,None]).all(0)].tolist()[0])\n",
    "        \n",
    "    \n",
    "    # Combine Features\n",
    "    final_features = list(set(jobTraining_featuers+layoff_featuers+eviction_featuers+materialHardship_featuers+grit_featuers+gpa_featuers))\n",
    "    selected_df = full[final_features]\n",
    "    \n",
    "    # Save CSV\n",
    "    selected_df.to_csv('../output/MI/data_univariate_feature_selection_'+str(k)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
